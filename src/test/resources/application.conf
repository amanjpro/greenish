# The jobs/data-sets to monitor
check-groups: {
  # The frequency of pulling data
  refresh-in-seconds: 30
  # The binding address of the HTTP server
  binding-address: "127.0.0.1"
  # The port on which the server is running
  port: 8080
  # Not all jobs are available at the begining of a period, an hourly job might
  # systematically appear at the end of an hour. A monthly job at the end of
  # the month, and etc. This is a global setting, for specifying the deafult
  # period-offset, if a job is expected to arrive at the end of the period, then
  # offset should be 1.
  # This set can be overridden by `group-period-check-offset` at group level,
  # and `job-period-check-offset` at job level.
  default-period-check-offset: 1
  # Additional environment variables to be passed
  # to the monitoring scripts, you can AWS profile
  # names here, for example:
  # AWS_PROFILE: "reader-profile"
  env: {
    VAR1: "foo"
    VAR2: "bar"
  }
  # Job groups, a group is a set of jobs/data-sets
  # that have some sort of logical relation
  groups: [
    {
      # Pick a human friendly name here
      group-name: "Group1",
      # More or less like `default-period-check-offset`, but this scoped to the
      # group only.  Can be overridden by `job-period-check-offset`.
      group-period-check-offset: 2
      # A group can have many jobs/data-sets to monitor
      job-entries: [
        {
          # Pick a human friendly name here
          job-name: "Job1"
          # An id to be used as a label for the exported Prometheus emtrics.
          # Each job will export internal metrics in a label to Prometheus,
          # which is controlled here. It is best to make sure that the id is
          # unique per job. But, it is not enforced.
          prometheus-id: "job_1"
          # A check-command is any executable program/script that, takes
          # `period` in the form of `period-pattern` below as the last
          # argument, and exits with 0 only if successful. You an add arguments
          # to the script here: `/etc/check job1 production` is perfectly
          # allowed.
          # In case the Greenish failed to run the script, please wrap it in a
          # shell-script and add shebang at the top. Java Process Builder can
          # fail to recognize some scripts/programs.
          check-command: "/tmp/first_script",
          # A valid date/time pattern. Please consult the following page for
          # more info:
          # https://docs.oracle.com/javase/8/docs/api/java/time/format/DateTimeFormatter.html#patterns
          # If the data-set is expected to appear at the first day of every
          # month, You can write a pattern like: yyyy-MM-01
          period-pattern: "yyyy-MM-dd-HH"
          # What is the expected run-frequency of the job?
          # Supported values: hourly, daily, monthly, annually
          job-run-frequency: "hourly"
          # More or less like `group-period-check-offset`, but this scoped to
          # this job only.
          job-period-check-offset: 3
          # What is the timezone of the periods in the data set. If you have two jobs,
          # one produced in Cairo, and follows Cairo timezone, and another in Canada
          # which follows UTC, you can configure them accordingly using this field.
          # Greenish respects the option when calling the monitoring script.
          timezone: "UTC"
          # How far back do you want to monitor? in this example we monitor
          # the last 24 datasets (hours)
          lookback: 24
          # The following are hints for Greenish, to check if a job is
          # at "great", "normal", "warn" or "critical" state
          great-at: 0
          normal-at: 1
          warn-at: 2
          error-at: 3
        },
        {
          job-name: "Job2"
          prometheus-id: "job_2"
          check-command: "/tmp/second_script job2",
          period-pattern: "yyyy-MM-dd-HH"
          job-run-frequency: "daily"
          timezone: "UTC"
          lookback: 24
          great-at: 0
          normal-at: 1
          warn-at: 2
          error-at: 3
        }
      ]
    },
    {
      group-name: "Group2",
      job-entries: [
        {
          job-name: "Job3"
          prometheus-id: "job_3"
          check-command: "/tmp/third_script",
          period-pattern: "yyyy-MM-dd"
          job-run-frequency: "monthly"
          timezone: "UTC"
          lookback: 3
          great-at: 0
          normal-at: 1
          warn-at: 2
          error-at: 3
        },
        {
          job-name: "Job4"
          prometheus-id: "job_4"
          check-command: "/tmp/fourth_script",
          period-pattern: "yyyy-01-01"
          job-run-frequency: "annually"
          timezone: "UTC"
          lookback: 3
          great-at: 0
          normal-at: 1
          warn-at: 2
          error-at: 3
        }
      ]
    }
  ]
}

# This section is used to tune the performance of Greenish
akka {
  # This is the thread-pool for running monitoring scripts
  # If Greenish is unresponsive, you should look into this.
  # As, monitoring scripts are expected to be IO bound, you
  # may want to maximize parallelism.
  refresh-dispatcher {
    type = Dispatcher
    executor = "thread-pool-executor"
    thread-pool-executor {
      fixed-pool-size = 100
    }
    throughput = 1
    mailbox-capacity = -1
  }
}
